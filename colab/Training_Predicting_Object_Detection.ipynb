{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gudPmnP_5yC"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics fiftyone opencv-python matplotlib\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import random\n",
        "import yaml\n",
        "import importlib.resources as pkg_resources\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import importlib.resources as pkg_resources\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Helper functions: load dataset YAMLs, normalize names, resolve splits\n",
        "# ------------------------------------------------------------------\n",
        "def load_dataset_cfg(name):\n",
        "    \"\"\"Loads an Ultralytics dataset YAML from ultralytics/cfg/datasets.\"\"\"\n",
        "    path = pkg_resources.files(\"ultralytics\") / \"cfg\" / \"datasets\" / name\n",
        "    path = str(path)\n",
        "    assert os.path.isfile(path), f\"{path} not found\"\n",
        "    with open(path, \"r\") as f:\n",
        "        cfg = yaml.safe_load(f)\n",
        "    return cfg, path\n",
        "\n",
        "\n",
        "def normalize_names(names):\n",
        "    \"\"\"Ensure names is a list of strings, regardless of dict/list form.\"\"\"\n",
        "    if isinstance(names, dict):\n",
        "        return [names[i] for i in range(len(names))]\n",
        "    elif isinstance(names, list):\n",
        "        return names\n",
        "    else:\n",
        "        raise TypeError(f\"Unsupported names type: {type(names)}\")\n",
        "\n",
        "\n",
        "def resolve_split(cfg, split_key):\n",
        "    \"\"\"\n",
        "    Resolve a dataset split (train/val) from a dataset cfg to an absolute path.\n",
        "    Handles relative paths from cfg['path'].\n",
        "    \"\"\"\n",
        "    split = cfg.get(split_key, None)\n",
        "    if split is None:\n",
        "        raise KeyError(f\"{split_key} not found in cfg\")\n",
        "\n",
        "    base_path = cfg.get(\"path\", \"\")\n",
        "\n",
        "    # If split is a list, just use the first element for now\n",
        "    if isinstance(split, (list, tuple)):\n",
        "        split = split[0]\n",
        "\n",
        "    if base_path:\n",
        "        split_path = os.path.join(base_path, split)\n",
        "    else:\n",
        "        split_path = split\n",
        "\n",
        "    return os.path.abspath(split_path)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Load COCO and HomeObjects-3K dataset configs\n",
        "# ------------------------------------------------------------------\n",
        "coco_cfg, coco_yaml_path = load_dataset_cfg(\"coco.yaml\")\n",
        "home_cfg, home_yaml_path = load_dataset_cfg(\"HomeObjects-3K.yaml\")\n",
        "\n",
        "print(\"COCO YAML path:\", coco_yaml_path)\n",
        "print(\"HomeObjects-3K YAML path:\", home_yaml_path)\n",
        "\n",
        "coco_names = normalize_names(coco_cfg[\"names\"])\n",
        "home_names = normalize_names(home_cfg[\"names\"])\n",
        "\n",
        "print(f\"COCO num classes: {len(coco_names)}\")\n",
        "print(f\"HomeObjects num classes: {len(home_names)}\")\n"
      ],
      "metadata": {
        "id": "VnC6onBx__oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Build union names: COCO + HomeObjects\n",
        "# Merge COCO \"dining table\" and HomeObjects \"table\" into \"table\"\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# 1) Start with all COCO classes (COCO numeric IDs stay the same)\n",
        "union_names = list(coco_names)\n",
        "\n",
        "# Find the COCO index for \"dining table\" and rename it to \"table\"\n",
        "try:\n",
        "    dining_table_idx = coco_names.index(\"dining table\")\n",
        "    print(\"COCO 'dining table' class index:\", dining_table_idx)\n",
        "    union_names[dining_table_idx] = \"table\"\n",
        "except ValueError:\n",
        "    dining_table_idx = None\n",
        "    print(\"[WARN] 'dining table' not found in COCO names! Will treat 'table' separately if present.\")\n",
        "\n",
        "# 2) Map HomeObjects classes into the union space\n",
        "home_to_union = {}\n",
        "\n",
        "for hid, hname in enumerate(home_names):\n",
        "    target_name = hname\n",
        "\n",
        "    # Simple normalization rules:\n",
        "    if hname.lower() == \"table\":\n",
        "        # Merge HomeObjects \"table\" into COCO's \"table\" class (if exists)\n",
        "        if \"table\" in union_names:\n",
        "            target_name = \"table\"\n",
        "        else:\n",
        "            target_name = \"table\"\n",
        "\n",
        "    if hname.lower() == \"sofa\":\n",
        "        # Map \"sofa\" to COCO \"couch\" if present\n",
        "        if \"couch\" in union_names:\n",
        "            target_name = \"couch\"\n",
        "\n",
        "    # If this name already exists in union_names, reuse that ID\n",
        "    if target_name in union_names:\n",
        "        union_id = union_names.index(target_name)\n",
        "    else:\n",
        "        union_id = len(union_names)\n",
        "        union_names.append(target_name)\n",
        "\n",
        "    home_to_union[hid] = union_id\n",
        "\n",
        "print(\"\\nExample HomeObjects mapping:\", list(home_to_union.items())[:10])\n",
        "\n",
        "# 3) Create dictionary form for YAMLs\n",
        "union_names_dict = {i: name for i, name in enumerate(union_names)}\n",
        "\n",
        "print(\"\\n[INFO] Final union class count (COCO+Home):\", len(union_names))\n",
        "print(\"[INFO] First 30 union classes:\", union_names[:30])\n",
        "\n",
        "# 4) Show where the splits resolve to (just info)\n",
        "coco_train_images_guess = resolve_split(coco_cfg, \"train\")\n",
        "coco_val_images_guess   = resolve_split(coco_cfg, \"val\")\n",
        "home_train_images_guess = resolve_split(home_cfg, \"train\")\n",
        "home_val_images_guess   = resolve_split(home_cfg, \"val\")\n",
        "\n",
        "print(\"\\nCOCO train images (guess):\", coco_train_images_guess)\n",
        "print(\"COCO val images (guess):  \", coco_val_images_guess)\n",
        "print(\"Home train images (guess):\", home_train_images_guess)\n",
        "print(\"Home val images (guess):  \", home_val_images_guess)\n"
      ],
      "metadata": {
        "id": "EauFiN7TACpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Unzip all Roboflow YOLOv8 datasets from Drive\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# Folder in Drive containing your env zips\n",
        "ENV_ZIP_DIR = Path(\"/content/drive/MyDrive/New-Yolo-Classes-Data/New_Yolo_Data\")\n",
        "\n",
        "# Where to extract them in the Colab filesystem\n",
        "ENV_EXTRACT_ROOT = Path(\"/content/env_datasets\")\n",
        "ENV_EXTRACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Find all .zip files\n",
        "env_zip_files = sorted([p for p in ENV_ZIP_DIR.iterdir() if p.suffix == \".zip\"])\n",
        "\n",
        "print(\"[INFO] Found env ZIP files:\")\n",
        "for z in env_zip_files:\n",
        "    print(\"  •\", z.name)\n",
        "\n",
        "# Extract each zip to its own folder\n",
        "extracted_datasets = []\n",
        "for zip_path in env_zip_files:\n",
        "    target_dir = ENV_EXTRACT_ROOT / zip_path.stem\n",
        "    if not target_dir.exists():\n",
        "        print(f\"[INFO] Extracting {zip_path.name} → {target_dir}\")\n",
        "        target_dir.mkdir(parents=True, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "            zf.extractall(target_dir)\n",
        "    else:\n",
        "        print(f\"[INFO] Already extracted: {target_dir}\")\n",
        "    extracted_datasets.append(target_dir)\n",
        "\n",
        "print(\"\\n[INFO] extracted_datasets:\")\n",
        "for d in extracted_datasets:\n",
        "    print(\"  •\", d)\n"
      ],
      "metadata": {
        "id": "fr9QVnWOFi1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Load env datasets (Roboflow YOLOv8 exports) and add classes to union\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# This must match where you unzipped the Roboflow zips:\n",
        "ENV_ROOT = Path(\"/content/env_datasets\")\n",
        "\n",
        "print(\"[INFO] ENV_ROOT:\", ENV_ROOT)\n",
        "print(\"[INFO] ENV_ROOT exists:\", ENV_ROOT.exists())\n",
        "if ENV_ROOT.exists():\n",
        "    print(\"[INFO] Contents of ENV_ROOT:\")\n",
        "    for p in ENV_ROOT.iterdir():\n",
        "        print(\"   \", p, \"(dir:\" , p.is_dir(), \")\")\n",
        "\n",
        "env_sets = []      # list of {folder, train, val, names}\n",
        "rf_to_union = {}   # folder name -> {local_id -> union_id}\n",
        "\n",
        "\n",
        "def normalize(name: str) -> str:\n",
        "    return name.lower().strip().replace(\"-\", \" \").replace(\"_\", \" \")\n",
        "\n",
        "# Build lookup for current union names\n",
        "union_lookup = {normalize(n): i for i, n in enumerate(union_names)}\n",
        "\n",
        "\n",
        "\n",
        "# Find ALL data.yaml files under env_datasets, not just top-level\n",
        "data_yamls = list(ENV_ROOT.rglob(\"data.yaml\"))\n",
        "print(\"\\n[INFO] Found data.yaml files:\")\n",
        "for dy in data_yamls:\n",
        "    print(\"   \", dy)\n",
        "\n",
        "for data_yaml in data_yamls:\n",
        "    ds_dir = data_yaml.parent  # directory that contains this data.yaml\n",
        "    print(f\"\\n[INFO] Loading env dataset from {data_yaml}\")\n",
        "\n",
        "    with open(data_yaml, \"r\") as f:\n",
        "        cfg = yaml.safe_load(f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    names_list = cfg.get(\"names\")\n",
        "    if names_list is None:\n",
        "      print(f\"  [WARN] No 'names' in {data_yaml}, skipping.\")\n",
        "      continue\n",
        "\n",
        "    # Ignore whatever 'train'/'val' say in data.yaml, and assume standard Roboflow layout:\n",
        "    #   <dataset_root>/train/images\n",
        "    #   <dataset_root>/valid/images\n",
        "    train_root = (ds_dir / \"train\" / \"images\").resolve()\n",
        "    val_root   = (ds_dir / \"valid\" / \"images\").resolve()\n",
        "\n",
        "    train_root = str(train_root)\n",
        "    val_root   = str(val_root)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"  train: {train_root}\")\n",
        "    print(f\"  val:   {val_root}\")\n",
        "    print(f\"  names: {names_list}\")\n",
        "\n",
        "    env_sets.append({\n",
        "        \"folder\": ds_dir.name,\n",
        "        \"train\": train_root,\n",
        "        \"val\": val_root,\n",
        "        \"names\": names_list,\n",
        "    })\n",
        "\n",
        "# Now integrate these names into the union space\n",
        "print(\"\\n[INFO] Integrating env datasets into union class space...\")\n",
        "for ds in env_sets:\n",
        "    ds_map = {}\n",
        "    for rf_id, rf_name in enumerate(ds[\"names\"]):\n",
        "        key = normalize(rf_name)\n",
        "        if key in union_lookup:\n",
        "            uid = union_lookup[key]\n",
        "        else:\n",
        "            uid = len(union_names)\n",
        "            union_names.append(rf_name)\n",
        "            union_lookup[key] = uid\n",
        "        ds_map[rf_id] = uid\n",
        "        print(f\"[MAP] {ds['folder']} class {rf_id} ({rf_name}) → union {uid}\")\n",
        "    rf_to_union[ds[\"folder\"]] = ds_map\n",
        "\n",
        "print(\"\\n[INFO] Final union class count (COCO+Home+env):\", len(union_names))\n",
        "print(\"[INFO] Number of env datasets loaded:\", len(env_sets))\n"
      ],
      "metadata": {
        "id": "fJOJaYjYhosQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Integrate Roboflow env datasets into union class space\n",
        "# ---------------------------------------------------------------\n",
        "'''\n",
        "def normalize(name: str) -> str:\n",
        "    return name.lower().strip().replace(\"-\", \" \").replace(\"_\", \" \")\n",
        "\n",
        "# Build lookup for current union names\n",
        "union_lookup = {normalize(n): i for i, n in enumerate(union_names)}\n",
        "\n",
        "rf_to_union = {}  # maps dataset folder -> { rf_id -> union_id }\n",
        "'''\n",
        "\n",
        "for ds in env_sets:\n",
        "    ds_map = {}\n",
        "    for rf_id, rf_name in enumerate(ds[\"names\"]):\n",
        "        key = normalize(rf_name)\n",
        "        if key in union_lookup:\n",
        "            uid = union_lookup[key]\n",
        "        else:\n",
        "            uid = len(union_names)\n",
        "            union_names.append(rf_name)\n",
        "            union_lookup[key] = uid\n",
        "        ds_map[rf_id] = uid\n",
        "        print(f\"[MAP] {ds['folder']} class {rf_id} ({rf_name}) → union {uid}\")\n",
        "    rf_to_union[ds[\"folder\"]] = ds_map\n",
        "\n",
        "# Rebuild union_names_dict now that we've extended it\n",
        "union_names_dict = {i: name for i, name in enumerate(union_names)}\n",
        "print(\"\\n[INFO] Final union class count (COCO+Home+env):\", len(union_names))\n"
      ],
      "metadata": {
        "id": "X0IbSP4Ic0v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics.data.utils import check_det_dataset\n",
        "from glob import glob\n",
        "import random, os\n",
        "\n",
        "# 1) Download / locate COCO using Ultralytics\n",
        "data_info = check_det_dataset(\"coco.yaml\")\n",
        "coco_train_root = os.path.abspath(data_info[\"train\"])\n",
        "coco_val_root   = os.path.abspath(data_info[\"val\"])\n",
        "\n",
        "print(\"Full COCO train root:\", coco_train_root)\n",
        "print(\"Full COCO val root:  \", coco_val_root)\n",
        "\n",
        "# 2) Build list of ALL train images\n",
        "if os.path.isdir(coco_train_root):\n",
        "    # train is a directory of images\n",
        "    all_coco_train_imgs = sorted(glob(os.path.join(coco_train_root, \"*.jpg\")))\n",
        "else:\n",
        "    # train is a .txt list – resolve any relative paths\n",
        "    base = os.path.dirname(coco_train_root)\n",
        "    all_coco_train_imgs = []\n",
        "    with open(coco_train_root, \"r\") as f:\n",
        "        for line in f:\n",
        "            p = line.strip()\n",
        "            if not p:\n",
        "                continue\n",
        "            if not os.path.isabs(p):\n",
        "                p = os.path.join(base, p)\n",
        "            if os.path.exists(p):\n",
        "                all_coco_train_imgs.append(os.path.abspath(p))\n",
        "            else:\n",
        "                print(\"Skipping missing image:\", p)\n",
        "\n",
        "print(\"Total COCO train images found:\", len(all_coco_train_imgs))\n",
        "\n",
        "# 3) Sample a random subset of 5k\n",
        "random.seed(0)\n",
        "subset_size = min(7000, len(all_coco_train_imgs))\n",
        "coco_train_subset = random.sample(all_coco_train_imgs, subset_size)\n",
        "\n",
        "subset_txt = \"coco_train5k.txt\"\n",
        "with open(subset_txt, \"w\") as f:\n",
        "    for p in coco_train_subset:\n",
        "        f.write(p + \"\\n\")\n",
        "\n",
        "coco_train_images = os.path.abspath(subset_txt)\n",
        "coco_val_images   = coco_val_root  # or make a val subset similarly\n",
        "\n",
        "print(\"Using COCO train subset file:\", coco_train_images)\n",
        "print(\"Using COCO val root:\", coco_val_images)\n"
      ],
      "metadata": {
        "id": "g0apTP-6ALq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from ultralytics.data.utils import check_det_dataset\n",
        "import os, yaml\n",
        "\n",
        "\n",
        "# Ensure HomeObjects-3K is downloaded and get its real paths\n",
        "home_info = check_det_dataset(\"HomeObjects-3K.yaml\")  # downloads if needed\n",
        "home_train_images = os.path.abspath(home_info[\"train\"])\n",
        "home_val_images   = os.path.abspath(home_info[\"val\"])\n",
        "\n",
        "print(\"Resolved Home train images:\", home_train_images)\n",
        "print(\"Resolved Home val images:  \", home_val_images)\n",
        "\n"
      ],
      "metadata": {
        "id": "xMRx6m9eAPWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Write union YAMLs: COCO + HomeObjects + Roboflow env datasets\n",
        "# ---------------------------------------------------------------\n",
        "union_names_dict = {i: name for i, name in enumerate(union_names)}\n",
        "\n",
        "def write_yaml(path, data):\n",
        "    with open(path, \"w\") as f:\n",
        "        yaml.safe_dump(data, f, sort_keys=False)\n",
        "    print(\"[INFO] Wrote\", path)\n",
        "\n",
        "# 1) Combined COCO + HomeObjects + env datasets for training\n",
        "train_paths = [\n",
        "    coco_train_images,\n",
        "    home_train_images,\n",
        "    home_train_images,  # oversample HomeObjects a bit\n",
        "]\n",
        "\n",
        "val_paths = [\n",
        "    coco_val_images,\n",
        "    home_val_images,\n",
        "]\n",
        "\n",
        "# Add env dataset paths, but only if the directory actually exists\n",
        "for ds in env_sets:\n",
        "    t = ds[\"train\"]\n",
        "    v = ds[\"val\"]\n",
        "\n",
        "    if t and os.path.isdir(t):\n",
        "        train_paths.append(t)\n",
        "    else:\n",
        "        print(f\"[WARN] Skipping env train path for {ds['folder']}: {t}\")\n",
        "\n",
        "    if v and os.path.isdir(v):\n",
        "        val_paths.append(v)\n",
        "    else:\n",
        "        print(f\"[WARN] Skipping env val path for {ds['folder']}: {v}\")\n",
        "\n",
        "print(\"\\n[INFO] Final train paths:\")\n",
        "for p in train_paths:\n",
        "    print(\"  \", p)\n",
        "\n",
        "print(\"\\n[INFO] Final val paths:\")\n",
        "for p in val_paths:\n",
        "    print(\"  \", p)\n",
        "\n",
        "coco_home_env_union = {\n",
        "    \"path\": \"\",\n",
        "    \"train\": train_paths,\n",
        "    \"val\": val_paths,\n",
        "    \"names\": union_names_dict,\n",
        "}\n",
        "write_yaml(\"coco_home_env_union.yaml\", coco_home_env_union)\n",
        "print(\"\\n[INFO] Wrote coco_home_env_union.yaml\")"
      ],
      "metadata": {
        "id": "PeLS8WMaATWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "\n",
        "from ultralytics.data.utils import check_det_dataset\n",
        "\n",
        "# 1) Ask Ultralytics where HomeObjects-3K really lives\n",
        "home_info = check_det_dataset(\"HomeObjects-3K.yaml\")\n",
        "home_train_images = os.path.abspath(home_info[\"train\"])\n",
        "home_val_images   = os.path.abspath(home_info[\"val\"])\n",
        "\n",
        "print(\"Home train images:\", home_train_images)\n",
        "print(\"Home val images:  \", home_val_images)\n",
        "\n",
        "# 2) Derive labels root by replacing 'images' with 'labels'\n",
        "def images_to_labels_dir(images_dir):\n",
        "    if \"images\" in images_dir:\n",
        "        return images_dir.replace(os.sep + \"images\", os.sep + \"labels\")\n",
        "    else:\n",
        "        return os.path.join(os.path.dirname(images_dir), \"labels\")\n",
        "\n",
        "home_labels_root_train = images_to_labels_dir(home_train_images)\n",
        "home_labels_root_val   = images_to_labels_dir(home_val_images)\n",
        "\n",
        "print(\"Home train labels root:\", home_labels_root_train)\n",
        "print(\"Home val labels root:  \", home_labels_root_val)\n",
        "\n",
        "# 3) Collect all label files and list unique IDs used\n",
        "label_files = glob.glob(os.path.join(home_labels_root_train, \"**\", \"*.txt\"), recursive=True)\n",
        "label_files += glob.glob(os.path.join(home_labels_root_val, \"**\", \"*.txt\"), recursive=True)\n",
        "\n",
        "used_ids = set()\n",
        "for lf in label_files:\n",
        "    with open(lf, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if not parts:\n",
        "                continue\n",
        "            cid = int(float(parts[0]))\n",
        "            used_ids.add(cid)\n",
        "\n",
        "print(\"Class IDs used in HomeObjects labels:\", sorted(used_ids))\n"
      ],
      "metadata": {
        "id": "iv9R8WA7AVYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This assumes you still have `home_to_union` dict and `home_cfg` in memory.\n",
        "# If not, reload HomeObjects-3K.yaml and rebuild them as before.\n",
        "\n",
        "def remap_homeobjects_labels_to_union_labels(home_labels_roots, home_to_union):\n",
        "    \"\"\"\n",
        "    Remaps class IDs in YOLO label files under the given roots using home_to_union mapping.\n",
        "    \"\"\"\n",
        "    import glob\n",
        "\n",
        "    for root in home_labels_roots:\n",
        "        if not os.path.isdir(root):\n",
        "            print(f\"[WARN] Labels root not found: {root}\")\n",
        "            continue\n",
        "\n",
        "        txt_files = glob.glob(os.path.join(root, \"**\", \"*.txt\"), recursive=True)\n",
        "        print(f\"[INFO] Remapping {len(txt_files)} label files under {root}...\")\n",
        "\n",
        "        for lf in txt_files:\n",
        "            with open(lf, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            new_lines = []\n",
        "            changed = False\n",
        "\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if not parts:\n",
        "                    continue\n",
        "\n",
        "                old_id = int(float(parts[0]))\n",
        "                # Only remap HomeObjects IDs; leave anything else alone\n",
        "                if old_id in home_to_union:\n",
        "                    new_id = home_to_union[old_id]\n",
        "                    parts[0] = str(new_id)\n",
        "                    changed = True\n",
        "\n",
        "                new_lines.append(\" \".join(parts))\n",
        "\n",
        "            if changed:\n",
        "                with open(lf, \"w\") as f:\n",
        "                    f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
        "\n",
        "    print(\"[INFO] Finished remapping HomeObjects labels to union IDs.\")\n",
        "\n",
        "\n",
        "# Call it with the TRAIN + VAL label roots discovered above\n",
        "home_labels_roots = [home_labels_root_train, home_labels_root_val]\n",
        "remap_homeobjects_labels_to_union_labels(home_labels_roots, home_to_union)\n"
      ],
      "metadata": {
        "id": "SfyO5AtNAV98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Remap Roboflow env dataset labels into the union class ID space\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "import glob\n",
        "\n",
        "def images_dir_to_labels_dir(images_dir: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert a typical YOLO/Roboflow images root to the corresponding\n",
        "    labels root, e.g.:\n",
        "      .../train/images  ->  .../train/labels\n",
        "      .../valid/images  ->  .../valid/labels\n",
        "    \"\"\"\n",
        "    from pathlib import Path\n",
        "\n",
        "    p = Path(images_dir)\n",
        "    parts = list(p.parts)\n",
        "    if \"images\" in parts:\n",
        "        idx = parts.index(\"images\")\n",
        "        parts[idx] = \"labels\"\n",
        "        return str(Path(*parts))\n",
        "\n",
        "    # Fallback: if \"images\" is not a separate path component\n",
        "    return str(p.parent.parent / \"labels\" / p.parent.name)\n",
        "\n",
        "\n",
        "def remap_env_labels_to_union(env_sets, rf_to_union):\n",
        "    \"\"\"\n",
        "    For each Roboflow env dataset in env_sets, rewrite its YOLO label\n",
        "    files so that class IDs use the global union IDs rather than the\n",
        "    dataset-local IDs.\n",
        "    \"\"\"\n",
        "    for ds in env_sets:\n",
        "        folder_name = ds[\"folder\"]           # e.g. \"Kitchen_Env_1\"\n",
        "        mapping = rf_to_union.get(folder_name, None)\n",
        "        if mapping is None:\n",
        "            print(f\"[WARN] No rf_to_union mapping for {folder_name}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n[INFO] Remapping env dataset '{folder_name}'\")\n",
        "\n",
        "        # derive labels roots from the train/val image roots\n",
        "        image_roots = [ds[\"train\"], ds[\"val\"]]\n",
        "        label_roots = [images_dir_to_labels_dir(r) for r in image_roots]\n",
        "\n",
        "        for labels_root in label_roots:\n",
        "            if not os.path.isdir(labels_root):\n",
        "                print(f\"  [WARN] Labels root not found: {labels_root}\")\n",
        "                continue\n",
        "\n",
        "            txt_files = glob.glob(os.path.join(labels_root, \"**\", \"*.txt\"),\n",
        "                                  recursive=True)\n",
        "            print(f\"  [INFO] Remapping {len(txt_files)} label files under {labels_root}...\")\n",
        "\n",
        "            for lf in txt_files:\n",
        "                with open(lf, \"r\") as f:\n",
        "                    lines = f.readlines()\n",
        "\n",
        "                new_lines = []\n",
        "                changed = False\n",
        "                for line in lines:\n",
        "                    parts = line.strip().split()\n",
        "                    if not parts:\n",
        "                        continue\n",
        "\n",
        "                    # local class ID within this Roboflow dataset\n",
        "                    local_id = int(float(parts[0]))\n",
        "                    if local_id not in mapping:\n",
        "                        # if it's some unexpected ID, leave the line as-is\n",
        "                        print(f\"    [WARN] class {local_id} not in mapping for {lf}, leaving as-is.\")\n",
        "                        new_lines.append(line.strip())\n",
        "                        continue\n",
        "\n",
        "                    union_id = mapping[local_id]\n",
        "                    if str(union_id) != parts[0]:\n",
        "                        parts[0] = str(union_id)\n",
        "                        changed = True\n",
        "                    new_lines.append(\" \".join(parts))\n",
        "\n",
        "                if changed:\n",
        "                    with open(lf, \"w\") as f:\n",
        "                        f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
        "\n",
        "        print(f\"[INFO] Finished remapping env dataset '{folder_name}'.\")\n",
        "\n",
        "\n",
        "# Actually run the remap for all env datasets\n",
        "remap_env_labels_to_union(env_sets, rf_to_union)\n"
      ],
      "metadata": {
        "id": "QAVo248-mxK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find IDs for every class\n",
        "\n",
        "for i, name in enumerate(union_names):\n",
        "    print(i, name)\n"
      ],
      "metadata": {
        "id": "MVFobj4cAY5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "KEEP_IDS = [0, 15, 16, 24, 25, 26, 28, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 91]\n"
      ],
      "metadata": {
        "id": "gi5ziutqAf8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len(union_names):\", len(union_names))\n",
        "print(\"env_sets length:\", len(env_sets))\n",
        "\n",
        "for ds in env_sets:\n",
        "    print(\"Env dataset:\", ds[\"folder\"])\n",
        "    print(\"  names:\", ds[\"names\"])\n"
      ],
      "metadata": {
        "id": "Aw8Er4Mis6fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i, hname in enumerate(home_names):\n",
        "    uid = home_to_union[i]\n",
        "    print(f\"Home {i}: {hname} -> union {uid}: {union_names[uid]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pG2aTYBXAa_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len(union_names):\", len(union_names))\n",
        "print(\"env_sets length:\", len(env_sets))\n",
        "for ds in env_sets:\n",
        "    print(ds[\"folder\"])\n",
        "    print(\"  train:\", ds[\"train\"], \"exists:\", os.path.isdir(ds[\"train\"]))\n",
        "    print(\"  val:  \", ds[\"val\"],   \"exists:\", os.path.isdir(ds[\"val\"]))\n"
      ],
      "metadata": {
        "id": "SL8dNP_P8LwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = YOLO(\"yolov8n.pt\")  # COCO-pretrained starting point\n",
        "\n",
        "#calculate how many layers are in model (for freezing)\n",
        "num_modules = len(list(model.model.model))\n",
        "\n",
        "\n",
        "model.train(\n",
        "    data=\"coco_home_env_union.yaml\",\n",
        "    epochs=50,          # fewer epochs, let early stopping do its thing\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    lr0=5e-4,           # lower base LR to avoid big shifts\n",
        "    lrf=0.01,\n",
        "    freeze=num_modules-2,  # or freeze=num_modules-2 if you prefer your existing scheme\n",
        "    patience=10,\n",
        "    project=\"runs_union\",\n",
        "    name=\"yolov8n_union_coco5k_home_robo\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "#best so far\n",
        "model.train(\n",
        "    data=\"coco_home_union.yaml\",\n",
        "    epochs=50,          # fewer epochs\n",
        "    #classes=KEEP_IDS,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    lr0=0.001,          # lower base LR (default is ~0.01)\n",
        "    lrf=0.01,           # stronger decay, ends very small\n",
        "    freeze=num_modules-2,          # freeze layers\n",
        "    patience=10,\n",
        "    project=\"runs_union\",\n",
        "    name=\"yolov8n_union_coco_home_gentle\",\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "vObVBI5cAhaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(glob.glob(\"runs_union/**/weights/best*.pt\", recursive=True))\n"
      ],
      "metadata": {
        "id": "OL7I2Jc3Axw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the union-trained model\n",
        "\n",
        "base_model = YOLO(\"yolov8n.pt\")\n",
        "union_model = YOLO(\"runs_union/yolov8n_union_coco5k_home/weights/best.pt\")\n",
        "\n",
        "\n",
        "\n",
        "def print_metrics(metrics, label=\"\"):\n",
        "    print(f\"{label} MODEL PERFORMANCE\")\n",
        "    print(f\"mAP@50:     {metrics.box.map50:.3f}\")\n",
        "    print(f\"mAP@50-95:  {metrics.box.map:.3f}\")\n",
        "    print(f\"Precision:  {metrics.box.mp:.3f}\")\n",
        "    print(f\"Recall:     {metrics.box.mr:.3f}\")\n",
        "    print(f\"F1 Score:   {metrics.box.f1[0]:.3f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gZeaNnPMAypI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# COCO (base model)\n",
        "metrics_coco = base_model.val(data=\"coco_union.yaml\", verbose=False)\n",
        "print_metrics(metrics_coco, \"BASE MODEL on COCO128\")\n",
        "\n",
        "# HomeObjects performance (base model)\n",
        "metrics_home = base_model.val(data=\"homeobjects_union.yaml\", verbose=False)\n",
        "print_metrics(metrics_home, \"BASE MODEL on HomeObjects-3K\")\n",
        "'''\n",
        "\n",
        "\n",
        "# COCO (fine-tuned model)\n",
        "metrics_coco = union_model.val(data=\"coco_union.yaml\", verbose=False)\n",
        "print_metrics(metrics_coco, \"UNION MODEL on COCO128\")\n",
        "\n",
        "# HomeObjects performance (fine-tuned model)\n",
        "metrics_home = union_model.val(data=\"homeobjects_union.yaml\", verbose=False)\n",
        "print_metrics(metrics_home, \"UNION MODEL on HomeObjects-3K\")\n"
      ],
      "metadata": {
        "id": "HLEJKftcA0t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save to drive"
      ],
      "metadata": {
        "id": "nyVEJ7uvA7_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Example for Ultralytics YOLOv8\n",
        "import shutil\n",
        "\n",
        "# Path to the trained weights in Colab's temporary storage\n",
        "source_best_weights = 'runs_union/yolov8n_union_coco5k_home_robo3/weights/best.pt'\n",
        "\n",
        "# Destination path in Google Drive\n",
        "destination_folder = '/content/drive/MyDrive/BestYoloModel'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "import os\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Copy the best weights\n",
        "shutil.copy(source_best_weights, os.path.join(destination_folder, 'YOLOModel6_withRobo.pt'))\n",
        "\n",
        "print(f\"YOLO model weights saved to {destination_folder}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "J_0pvn11A3eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Video"
      ],
      "metadata": {
        "id": "tV80-BUDBDsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_yolo_video(model, video_path):\n",
        "    \"\"\"\n",
        "    Test YOLOv8 model on a video.\n",
        "\n",
        "    Args:\n",
        "        model: The loaded YOLOv8 model.\n",
        "        video_path: The path to the input video file.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {video_path}\")\n",
        "        return\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Perform inference on the frame\n",
        "        results = model(frame, classes=KEEP_IDS)#, conf=0.2)\n",
        "        res = results[0]\n",
        "\n",
        "        # Display the frame with detections\n",
        "        plt.imshow(res.plot())\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    cap.release()\n",
        "    print(\"Video processing finished.\")"
      ],
      "metadata": {
        "id": "zwWEJ5zdA7ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_yolo_video(YOLO(\"runs_union/yolov8n_union_coco_home_gentle/weights/best.pt\"), \"/content/215475_small.mp4\")\n",
        "\n",
        "test_yolo_video(YOLO(\"runs_union/yolov8n_union_coco5k_home_robo3/weights/best.pt\"), \"/content/215475_small.mp4\")"
      ],
      "metadata": {
        "id": "nQip6A2OBBPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def test_yolo_video_with_positions(model, video_path, keep_ids=None, show=True):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_idx = 0\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"[ERROR] Could not open video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Try to get class names from the model once\n",
        "    model_names = None\n",
        "    try:\n",
        "        # works for Ultralytics YOLO models\n",
        "        model_names = model.model.names\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Run YOLO on this frame\n",
        "        if keep_ids is not None:\n",
        "            results = model(frame, classes=keep_ids)\n",
        "        else:\n",
        "            results = model(frame)\n",
        "\n",
        "        res = results[0]\n",
        "\n",
        "        # Fallback: if we didn’t get names from the model, try from the result\n",
        "        names = model_names or getattr(res, \"names\", None)\n",
        "\n",
        "        # Get boxes in xywh format (center x,y,width,height)\n",
        "        if res.boxes is not None and len(res.boxes) > 0:\n",
        "            boxes_xywh = res.boxes.xywh.cpu().numpy()\n",
        "            clss       = res.boxes.cls.cpu().numpy()\n",
        "            confs      = res.boxes.conf.cpu().numpy()\n",
        "        else:\n",
        "            boxes_xywh = []\n",
        "            clss       = []\n",
        "            confs      = []\n",
        "\n",
        "        print(f\"\\n[FRAME {frame_idx}] detections: {len(boxes_xywh)}\")\n",
        "\n",
        "        for (x, y, w, h), c, conf in zip(boxes_xywh, clss, confs):\n",
        "            cls_id = int(c)\n",
        "\n",
        "            # Resolve class name from names if available\n",
        "            cls_name = None\n",
        "            if names is not None:\n",
        "                # names can be list or dict\n",
        "                if isinstance(names, dict):\n",
        "                    cls_name = names.get(cls_id, None)\n",
        "                else:  # list/tuple\n",
        "                    if 0 <= cls_id < len(names):\n",
        "                        cls_name = names[cls_id]\n",
        "\n",
        "            if cls_name is None:\n",
        "                cls_name = f\"id_{cls_id}\"\n",
        "\n",
        "            print(\n",
        "                f\"  {cls_name:20s} \"\n",
        "                f\"center=({x:.1f}, {y:.1f}), \"\n",
        "                f\"w={w:.1f}, h={h:.1f}, conf={conf:.2f}\"\n",
        "            )\n",
        "\n",
        "        # Optionally show the plotted frame with boxes\n",
        "        if show:\n",
        "            plotted = res.plot()  # draws boxes + labels\n",
        "            # res.plot() returns BGR when using OpenCV under the hood;\n",
        "            # if colors look off, flip channels:\n",
        "            plt.imshow(plotted[..., ::-1])\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n"
      ],
      "metadata": {
        "id": "KiG-U99BbchZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "baseModel = YOLO(\"yolov8n.pt\")\n",
        "modelTest = YOLO(\"/content/YOLOModel6_withRobo.pt\")\n",
        "test_yolo_video_with_positions(modelTest, \"/content/IMG_6406.MOV\", keep_ids=KEEP_IDS, show=True)\n"
      ],
      "metadata": {
        "id": "SZEEFeocwp1n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}